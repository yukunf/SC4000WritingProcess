{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58916ee6",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea56df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476ad30b",
   "metadata": {},
   "source": [
    "## 2. Feature Extraction Functions\n",
    "\n",
    "Extract different behavioural features from keystroke logs.\n",
    "We want to capture:\n",
    "\n",
    "- pauses (when people are thinking)\n",
    "- bursts (when they're typing continuously)\n",
    "- editing behaviour (how much they revise)\n",
    "- cursor movement (planning vs going back to edit)\n",
    "\n",
    "### 2.1 Base Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58441cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    \"\"\"Pull out the main features from the log data\"\"\"\n",
    "    \n",
    "    # Count up events and get basic stats\n",
    "    features = df.groupby(\"id\").agg(\n",
    "        events_count=('event_id', 'count'),\n",
    "        total_time=('up_time', 'max'),\n",
    "        total_chars=('word_count', 'max'),\n",
    "        mean_action_time=('action_time', 'mean'),\n",
    "        std_action_time=('action_time', 'std'),\n",
    "        max_action_time=('action_time', 'max'),\n",
    "        min_action_time=('action_time', 'min'),\n",
    "        \n",
    "        # Count different types of actions\n",
    "        backspace_count=('activity', lambda x: (x == \"Remove/Cut\").sum()),\n",
    "        paste_count=('activity', lambda x: (x == \"Paste\").sum()),\n",
    "        input_count=('activity', lambda x: (x == \"Input\").sum()),\n",
    "        move_count=('activity', lambda x: x.str.contains(\"Move\", na=False).sum()),\n",
    "        replace_count=('activity', lambda x: (x == \"Replace\").sum()),\n",
    "        nonproduction_count=('activity', lambda x: (x == \"Nonproduction\").sum()),\n",
    "        \n",
    "        # Where the cursor was\n",
    "        cursor_pos_mean=('cursor_position', 'mean'),\n",
    "        cursor_pos_std=('cursor_position', 'std'),\n",
    "        cursor_pos_max=('cursor_position', 'max'),\n",
    "        \n",
    "        # Word count stats\n",
    "        word_count_mean=('word_count', 'mean'),\n",
    "        word_count_std=('word_count', 'std'),\n",
    "        word_count_diff=('word_count', lambda x: x.max() - x.min()),\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Replace any missing values with 0\n",
    "    features = features.fillna(0)\n",
    "    \n",
    "    # Calculate some ratios\n",
    "    features['chars_per_min'] = features['total_chars'] / (features['total_time'] / 60000 + 1e-6)\n",
    "    features['events_per_min'] = features['events_count'] / (features['total_time'] / 60000 + 1e-6)\n",
    "    features['backspace_ratio'] = features['backspace_count'] / (features['input_count'] + 1)\n",
    "    features['paste_ratio'] = features['paste_count'] / (features['events_count'] + 1)\n",
    "    features['replace_ratio'] = features['replace_count'] / (features['events_count'] + 1)\n",
    "    features['nonproduction_ratio'] = features['nonproduction_count'] / (features['events_count'] + 1)\n",
    "    features['revision_ratio'] = (features['backspace_count'] + features['replace_count']) / (features['total_chars'] + 1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152b9352",
   "metadata": {},
   "source": [
    "### 2.2 Pause Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862bc7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pause_features(df):\n",
    "    \"\"\"Get features about pauses (gaps between keystrokes)\"\"\"\n",
    "    df = df.sort_values([\"id\", \"down_time\"]).copy()\n",
    "    df[\"iki\"] = df.groupby(\"id\")[\"down_time\"].diff()\n",
    "    \n",
    "    # Count pauses at different thresholds (2s, 5s, 10s)\n",
    "    pause_2s = df.groupby(\"id\")[\"iki\"].apply(lambda x: (x > 2000).sum()).rename(\"pause_2s_count\")\n",
    "    pause_5s = df.groupby(\"id\")[\"iki\"].apply(lambda x: (x > 5000).sum()).rename(\"pause_5s_count\")\n",
    "    pause_10s = df.groupby(\"id\")[\"iki\"].apply(lambda x: (x > 10000).sum()).rename(\"pause_10s_count\")\n",
    "    \n",
    "    # Basic pause stats\n",
    "    mean_pause = df.groupby(\"id\")[\"iki\"].mean().rename(\"mean_pause\")\n",
    "    median_pause = df.groupby(\"id\")[\"iki\"].median().rename(\"median_pause\")\n",
    "    std_pause = df.groupby(\"id\")[\"iki\"].std().rename(\"std_pause\")\n",
    "    max_pause = df.groupby(\"id\")[\"iki\"].max().rename(\"max_pause\")\n",
    "    min_pause = df.groupby(\"id\")[\"iki\"].min().rename(\"min_pause\")\n",
    "    \n",
    "    return pause_2s, pause_5s, pause_10s, mean_pause, median_pause, std_pause, max_pause, min_pause\n",
    "\n",
    "\n",
    "def burst_features(df):\n",
    "    \"\"\"Get features about bursts (when they're typing continuously)\"\"\"\n",
    "    df = df.sort_values([\"id\", \"down_time\"]).copy()\n",
    "    df[\"iki\"] = df.groupby(\"id\")[\"down_time\"].diff()\n",
    "    df[\"burst\"] = (df[\"iki\"] > 2000).astype(int)\n",
    "    df[\"burst_id\"] = df.groupby(\"id\")[\"burst\"].cumsum()\n",
    "    \n",
    "    burst_len = df.groupby([\"id\", \"burst_id\"]).size()\n",
    "    avg_burst = burst_len.groupby(\"id\").mean().rename(\"avg_burst\")\n",
    "    max_burst = burst_len.groupby(\"id\").max().rename(\"max_burst\")\n",
    "    std_burst = burst_len.groupby(\"id\").std().rename(\"std_burst\")\n",
    "    \n",
    "    return avg_burst, max_burst, std_burst\n",
    "\n",
    "\n",
    "def p_burst_features(df):\n",
    "    \"\"\"Get P-burst features (how many words per burst)\"\"\"\n",
    "    df = df.sort_values([\"id\", \"down_time\"]).copy()\n",
    "    df[\"iki\"] = df.groupby(\"id\")[\"down_time\"].diff()\n",
    "    \n",
    "    # P-bursts: pauses longer than 2s\n",
    "    df[\"p_burst\"] = (df[\"iki\"] > 2000).astype(int)\n",
    "    df[\"p_burst_id\"] = df.groupby(\"id\")[\"p_burst\"].cumsum()\n",
    "    \n",
    "    # How many words in each burst\n",
    "    p_burst_words = df.groupby([\"id\", \"p_burst_id\"])[\"word_count\"].apply(lambda x: x.max() - x.min())\n",
    "    avg_words_per_p_burst = p_burst_words.groupby(\"id\").mean().rename(\"avg_words_per_p_burst\")\n",
    "    \n",
    "    return avg_words_per_p_burst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ca6961",
   "metadata": {},
   "source": [
    "### 2.3 Activity Sequence & Text Change Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3801d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activity_sequence_features(df):\n",
    "    \"\"\"Get features from activity patterns and transitions\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for id_val in df['id'].unique():\n",
    "        id_df = df[df['id'] == id_val].sort_values('down_time')\n",
    "        activities = id_df['activity'].values\n",
    "        \n",
    "        # Track how activities transition from one to another\n",
    "        transitions = {}\n",
    "        for i in range(len(activities) - 1):\n",
    "            transition = f\"{activities[i]}->{activities[i+1]}\"\n",
    "            transitions[transition] = transitions.get(transition, 0) + 1\n",
    "        \n",
    "        # Common patterns\n",
    "        input_to_remove = transitions.get('Input->Remove/Cut', 0)\n",
    "        remove_to_input = transitions.get('Remove/Cut->Input', 0)\n",
    "        input_to_input = transitions.get('Input->Input', 0)\n",
    "        paste_to_input = transitions.get('Paste->Input', 0)\n",
    "        \n",
    "        # Find the longest streaks of the same activity\n",
    "        max_input_streak = 0\n",
    "        max_remove_streak = 0\n",
    "        current_input_streak = 0\n",
    "        current_remove_streak = 0\n",
    "        \n",
    "        for act in activities:\n",
    "            if act == 'Input':\n",
    "                current_input_streak += 1\n",
    "                max_input_streak = max(max_input_streak, current_input_streak)\n",
    "                current_remove_streak = 0\n",
    "            elif act == 'Remove/Cut':\n",
    "                current_remove_streak += 1\n",
    "                max_remove_streak = max(max_remove_streak, current_remove_streak)\n",
    "                current_input_streak = 0\n",
    "            else:\n",
    "                current_input_streak = 0\n",
    "                current_remove_streak = 0\n",
    "        \n",
    "        # How varied are the activities\n",
    "        unique_activities = len(set(activities))\n",
    "        activity_switches = sum(1 for i in range(len(activities)-1) if activities[i] != activities[i+1])\n",
    "        \n",
    "        features.append({\n",
    "            'id': id_val,\n",
    "            'input_to_remove_trans': input_to_remove,\n",
    "            'remove_to_input_trans': remove_to_input,\n",
    "            'input_to_input_trans': input_to_input,\n",
    "            'paste_to_input_trans': paste_to_input,\n",
    "            'max_input_streak': max_input_streak,\n",
    "            'max_remove_streak': max_remove_streak,\n",
    "            'unique_activities': unique_activities,\n",
    "            'activity_switches': activity_switches,\n",
    "            'activity_switch_rate': activity_switches / len(activities) if len(activities) > 0 else 0\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "def text_change_features(df):\n",
    "    \"\"\"Features about how the text changes\"\"\"\n",
    "    df = df.sort_values(['id', 'down_time']).copy()\n",
    "    \n",
    "    # How much text was added or removed\n",
    "    df['text_change'] = df.groupby('id')['word_count'].diff().fillna(0)\n",
    "    \n",
    "    features = df.groupby('id').agg(\n",
    "        total_text_produced=('text_change', lambda x: x[x > 0].sum()),\n",
    "        total_text_removed=('text_change', lambda x: abs(x[x < 0].sum())),\n",
    "        text_production_rate=('text_change', lambda x: x[x > 0].mean()),\n",
    "        text_removal_rate=('text_change', lambda x: x[x < 0].mean()),\n",
    "        max_text_addition=('text_change', 'max'),\n",
    "        max_text_removal=('text_change', 'min'),\n",
    "        text_volatility=('text_change', 'std'),\n",
    "        positive_text_changes=('text_change', lambda x: (x > 0).sum()),\n",
    "        negative_text_changes=('text_change', lambda x: (x < 0).sum()),\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate some more useful ratios\n",
    "    features['text_removal_ratio'] = features['total_text_removed'] / (features['total_text_produced'] + 1)\n",
    "    features['net_text_production'] = features['total_text_produced'] - features['total_text_removed']\n",
    "    features['text_efficiency'] = features['total_text_produced'] / (features['positive_text_changes'] + 1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ee2e3",
   "metadata": {},
   "source": [
    "### 2.4 Temporal & Velocity Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c863eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_based_features(df):\n",
    "    \"\"\"Features based on when things happen (early, middle, late)\"\"\"\n",
    "    df = df.sort_values(['id', 'down_time']).copy()\n",
    "    \n",
    "    # Split the writing session into three parts\n",
    "    df['time_percentile'] = df.groupby('id')['down_time'].rank(pct=True)\n",
    "    \n",
    "    features = []\n",
    "    for id_val in df['id'].unique():\n",
    "        id_df = df[df['id'] == id_val]\n",
    "        \n",
    "        # Split into early, middle, and late phases\n",
    "        early_phase = id_df[id_df['time_percentile'] <= 0.33]\n",
    "        middle_phase = id_df[(id_df['time_percentile'] > 0.33) & (id_df['time_percentile'] <= 0.67)]\n",
    "        late_phase = id_df[id_df['time_percentile'] > 0.67]\n",
    "        \n",
    "        features.append({\n",
    "            'id': id_val,\n",
    "            'early_events': len(early_phase),\n",
    "            'middle_events': len(middle_phase),\n",
    "            'late_events': len(late_phase),\n",
    "            'early_input_ratio': (early_phase['activity'] == 'Input').sum() / (len(early_phase) + 1),\n",
    "            'middle_input_ratio': (middle_phase['activity'] == 'Input').sum() / (len(middle_phase) + 1),\n",
    "            'late_input_ratio': (late_phase['activity'] == 'Input').sum() / (len(late_phase) + 1),\n",
    "            'early_remove_ratio': (early_phase['activity'] == 'Remove/Cut').sum() / (len(early_phase) + 1),\n",
    "            'late_remove_ratio': (late_phase['activity'] == 'Remove/Cut').sum() / (len(late_phase) + 1),\n",
    "            'middle_paste_ratio': (middle_phase['activity'] == 'Paste').sum() / (len(middle_phase) + 1),\n",
    "            'late_phase_activity': len(late_phase) / (len(id_df) + 1),\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "def keystroke_velocity_features(df):\n",
    "    \"\"\"Features about typing speed\"\"\"\n",
    "    df = df.sort_values(['id', 'down_time']).copy()\n",
    "    df['iki'] = df.groupby('id')['down_time'].diff()\n",
    "    \n",
    "    # Only look at actual typing events\n",
    "    input_df = df[df['activity'] == 'Input'].copy()\n",
    "    \n",
    "    if len(input_df) == 0:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    features = input_df.groupby('id').agg(\n",
    "        input_iki_mean=('iki', 'mean'),\n",
    "        input_iki_std=('iki', 'std'),\n",
    "        input_iki_median=('iki', 'median'),\n",
    "        input_iki_min=('iki', 'min'),\n",
    "        input_iki_max=('iki', 'max'),\n",
    "        fast_keystrokes=('iki', lambda x: (x < 100).sum()),\n",
    "        moderate_keystrokes=('iki', lambda x: ((x >= 100) & (x <= 1000)).sum()),\n",
    "        slow_keystrokes=('iki', lambda x: (x > 1000).sum()),\n",
    "    ).reset_index()\n",
    "    \n",
    "    # How consistent is the typing\n",
    "    features['keystroke_consistency'] = features['input_iki_std'] / (features['input_iki_mean'] + 1)\n",
    "    features['fast_keystroke_ratio'] = features['fast_keystrokes'] / (features['fast_keystrokes'] + features['moderate_keystrokes'] + features['slow_keystrokes'] + 1)\n",
    "    features['typing_rhythm_score'] = features['moderate_keystrokes'] / (features['fast_keystrokes'] + features['moderate_keystrokes'] + features['slow_keystrokes'] + 1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "\n",
    "def word_count_velocity_features(df):\n",
    "    \"\"\"Features about how word count changes\"\"\"\n",
    "    df = df.sort_values(['id', 'down_time']).copy()\n",
    "    \n",
    "    features = []\n",
    "    for id_val in df['id'].unique():\n",
    "        id_df = df[df['id'] == id_val]\n",
    "        \n",
    "        word_counts = id_df['word_count'].values\n",
    "        time_stamps = id_df['down_time'].values\n",
    "        \n",
    "        # How fast are words being added\n",
    "        if len(word_counts) > 1:\n",
    "            word_velocity = np.diff(word_counts) / (np.diff(time_stamps) + 1)\n",
    "            \n",
    "            features.append({\n",
    "                'id': id_val,\n",
    "                'avg_word_velocity': np.mean(word_velocity),\n",
    "                'max_word_velocity': np.max(word_velocity),\n",
    "                'min_word_velocity': np.min(word_velocity),\n",
    "                'std_word_velocity': np.std(word_velocity),\n",
    "                'positive_velocity_ratio': (word_velocity > 0).sum() / len(word_velocity)\n",
    "            })\n",
    "        else:\n",
    "            features.append({\n",
    "                'id': id_val,\n",
    "                'avg_word_velocity': 0,\n",
    "                'max_word_velocity': 0,\n",
    "                'min_word_velocity': 0,\n",
    "                'std_word_velocity': 0,\n",
    "                'positive_velocity_ratio': 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "def activity_timing_features(df):\n",
    "    \"\"\"How much time is spent on each type of activity\"\"\"\n",
    "    df = df.sort_values(['id', 'down_time']).copy()\n",
    "    \n",
    "    features = []\n",
    "    for id_val in df['id'].unique():\n",
    "        id_df = df[df['id'] == id_val]\n",
    "        \n",
    "        # Add up time for each activity\n",
    "        input_time = id_df[id_df['activity'] == 'Input']['action_time'].sum()\n",
    "        remove_time = id_df[id_df['activity'] == 'Remove/Cut']['action_time'].sum()\n",
    "        paste_time = id_df[id_df['activity'] == 'Paste']['action_time'].sum()\n",
    "        nonprod_time = id_df[id_df['activity'] == 'Nonproduction']['action_time'].sum()\n",
    "        \n",
    "        total_time = id_df['action_time'].sum()\n",
    "        \n",
    "        features.append({\n",
    "            'id': id_val,\n",
    "            'input_time_total': input_time,\n",
    "            'remove_time_total': remove_time,\n",
    "            'paste_time_total': paste_time,\n",
    "            'nonprod_time_total': nonprod_time,\n",
    "            'input_time_ratio': input_time / (total_time + 1),\n",
    "            'remove_time_ratio': remove_time / (total_time + 1),\n",
    "            'productive_time_ratio': (input_time + paste_time) / (total_time + 1),\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be927b9e",
   "metadata": {},
   "source": [
    "### 2.5 Revision & Cursor Movement Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b54449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revision_pattern_features(df):\n",
    "    \"\"\"Features about revision behaviour and editing patterns\"\"\"\n",
    "    df = df.sort_values(['id', 'down_time']).copy()\n",
    "    \n",
    "    features = []\n",
    "    for id_val in df['id'].unique():\n",
    "        id_df = df[df['id'] == id_val]\n",
    "        \n",
    "        # Where in the text are they making changes\n",
    "        cursor_positions = id_df['cursor_position'].values\n",
    "        activities = id_df['activity'].values\n",
    "        word_counts = id_df['word_count'].values\n",
    "        \n",
    "        # Count edits at start, middle, and end\n",
    "        revisions_start = 0\n",
    "        revisions_middle = 0\n",
    "        revisions_end = 0\n",
    "        \n",
    "        for i, (pos, act, wc) in enumerate(zip(cursor_positions, activities, word_counts)):\n",
    "            if act in ['Remove/Cut', 'Replace'] and wc > 0:\n",
    "                relative_pos = pos / (wc + 1)\n",
    "                if relative_pos < 0.33:\n",
    "                    revisions_start += 1\n",
    "                elif relative_pos < 0.67:\n",
    "                    revisions_middle += 1\n",
    "                else:\n",
    "                    revisions_end += 1\n",
    "        \n",
    "        # Look for write-then-edit cycles\n",
    "        review_cycles = 0\n",
    "        in_writing = False\n",
    "        for act in activities:\n",
    "            if act == 'Input':\n",
    "                in_writing = True\n",
    "            elif act in ['Remove/Cut', 'Replace'] and in_writing:\n",
    "                review_cycles += 1\n",
    "                in_writing = False\n",
    "        \n",
    "        # How often they go backwards to edit\n",
    "        backward_movements = sum(1 for i in range(len(cursor_positions)-1) \n",
    "                                if cursor_positions[i+1] < cursor_positions[i])\n",
    "        \n",
    "        total_revisions = revisions_start + revisions_middle + revisions_end\n",
    "        \n",
    "        features.append({\n",
    "            'id': id_val,\n",
    "            'revisions_at_start': revisions_start,\n",
    "            'revisions_at_middle': revisions_middle,\n",
    "            'revisions_at_end': revisions_end,\n",
    "            'total_revisions': total_revisions,\n",
    "            'review_cycles': review_cycles,\n",
    "            'backward_movements': backward_movements,\n",
    "            'early_revision_ratio': revisions_start / (total_revisions + 1),\n",
    "            'end_revision_ratio': revisions_end / (total_revisions + 1),\n",
    "            'revision_density': total_revisions / (len(id_df) + 1),\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "def cursor_movement_features(df):\n",
    "    \"\"\"Features about how the cursor moves around\"\"\"\n",
    "    df = df.sort_values(['id', 'down_time']).copy()\n",
    "    df['cursor_jump'] = df.groupby('id')['cursor_position'].diff().abs()\n",
    "    \n",
    "    features = df.groupby('id').agg(\n",
    "        avg_cursor_jump=('cursor_jump', 'mean'),\n",
    "        max_cursor_jump=('cursor_jump', 'max'),\n",
    "        total_cursor_movement=('cursor_jump', 'sum'),\n",
    "        small_cursor_jumps=('cursor_jump', lambda x: (x <= 5).sum()),\n",
    "        medium_cursor_jumps=('cursor_jump', lambda x: ((x > 5) & (x <= 50)).sum()),\n",
    "        large_cursor_jumps=('cursor_jump', lambda x: (x > 50).sum()),\n",
    "        cursor_jump_std=('cursor_jump', 'std'),\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Where is the cursor most of the time\n",
    "    cursor_at_end = df.groupby('id').apply(\n",
    "        lambda x: (x['cursor_position'] == x['word_count']).sum() / len(x)\n",
    "    ).rename('cursor_at_end_ratio')\n",
    "    \n",
    "    cursor_at_start = df.groupby('id').apply(\n",
    "        lambda x: (x['cursor_position'] == 0).sum() / len(x)\n",
    "    ).rename('cursor_at_start_ratio')\n",
    "    \n",
    "    features = features.merge(cursor_at_end, on='id', how='left')\n",
    "    features = features.merge(cursor_at_start, on='id', how='left')\n",
    "    \n",
    "    # Are they mostly writing forwards\n",
    "    features['forward_writing_tendency'] = features['cursor_at_end_ratio']\n",
    "    features['navigation_complexity'] = features['large_cursor_jumps'] / (features['total_cursor_movement'] + 1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9954fea2",
   "metadata": {},
   "source": [
    "### 2.6 Rolling Window & Distribution Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c3daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_features(df, window=10):\n",
    "    \"\"\"Look at trends over time using a sliding window\"\"\"\n",
    "    df = df.sort_values(['id', 'down_time']).copy()\n",
    "    \n",
    "    features = []\n",
    "    for id_val in df['id'].unique():\n",
    "        id_df = df[df['id'] == id_val]\n",
    "        \n",
    "        if len(id_df) < window:\n",
    "            features.append({\n",
    "                'id': id_val,\n",
    "                'action_time_rolling_mean': id_df['action_time'].mean(),\n",
    "                'action_time_rolling_std': id_df['action_time'].std(),\n",
    "                'word_count_rolling_trend': 0,\n",
    "                'action_time_trend': 0,\n",
    "                'action_time_acceleration': 0\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        # Calculate moving averages\n",
    "        action_rolling = id_df['action_time'].rolling(window=window, min_periods=1)\n",
    "        word_rolling = id_df['word_count'].rolling(window=window, min_periods=1)\n",
    "        \n",
    "        # Are things speeding up or slowing down\n",
    "        word_trend = (word_rolling.mean().iloc[-1] - word_rolling.mean().iloc[0]) if len(id_df) >= window else 0\n",
    "        action_trend = (action_rolling.mean().iloc[-1] - action_rolling.mean().iloc[0]) if len(id_df) >= window else 0\n",
    "        \n",
    "        features.append({\n",
    "            'id': id_val,\n",
    "            'action_time_rolling_mean': action_rolling.mean().mean(),\n",
    "            'action_time_rolling_std': action_rolling.std().mean(),\n",
    "            'word_count_rolling_trend': word_trend,\n",
    "            'action_time_trend': action_trend,\n",
    "            'action_time_acceleration': action_rolling.mean().diff().mean()\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(features)\n",
    "\n",
    "\n",
    "def action_time_distribution_features(df):\n",
    "    \"\"\"Statistical properties of action times\"\"\"\n",
    "    features = df.groupby('id')['action_time'].agg([\n",
    "        ('action_time_q25', lambda x: x.quantile(0.25)),\n",
    "        ('action_time_q75', lambda x: x.quantile(0.75)),\n",
    "        ('action_time_iqr', lambda x: x.quantile(0.75) - x.quantile(0.25)),\n",
    "        ('action_time_skew', lambda x: x.skew()),\n",
    "        ('action_time_kurtosis', lambda x: x.kurtosis()),\n",
    "    ]).reset_index()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104a6f7",
   "metadata": {},
   "source": [
    "### 2.7 Advanced Event Timing Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed5d93",
   "metadata": {},
   "source": [
    "## 3. Main Feature Builder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b6ae70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_all_features(df):\n",
    "    \"\"\"\n",
    "    Main function to build all features from log data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        Input log data with columns: id, event_id, down_time, up_time, \n",
    "        action_time, activity, cursor_position, word_count\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    DataFrame with all extracted features\n",
    "    \"\"\"\n",
    "    print(\"Building all features...\")\n",
    "    \n",
    "    # Base features\n",
    "    print(\"  - Base features\")\n",
    "    features = extract_features(df)\n",
    "    \n",
    "    # Pause features\n",
    "    print(\"  - Pause features\")\n",
    "    pause_feats = pause_features(df)\n",
    "    for feat in pause_feats:\n",
    "        features = features.merge(feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Burst features\n",
    "    print(\"  - Burst features\")\n",
    "    burst_feats = burst_features(df)\n",
    "    for feat in burst_feats:\n",
    "        features = features.merge(feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # P-burst features\n",
    "    print(\"  - P-burst features\")\n",
    "    p_burst_feat = p_burst_features(df)\n",
    "    features = features.merge(p_burst_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Activity sequence features\n",
    "    print(\"  - Activity sequence features\")\n",
    "    activity_seq_feat = activity_sequence_features(df)\n",
    "    features = features.merge(activity_seq_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Text change features\n",
    "    print(\"  - Text change features\")\n",
    "    text_feat = text_change_features(df)\n",
    "    features = features.merge(text_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Time-based features\n",
    "    print(\"  - Time-based features\")\n",
    "    time_feat = time_based_features(df)\n",
    "    features = features.merge(time_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Keystroke velocity features\n",
    "    print(\"  - Keystroke velocity features\")\n",
    "    keystroke_feat = keystroke_velocity_features(df)\n",
    "    if not keystroke_feat.empty:\n",
    "        features = features.merge(keystroke_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Revision pattern features\n",
    "    print(\"  - Revision pattern features\")\n",
    "    revision_feat = revision_pattern_features(df)\n",
    "    features = features.merge(revision_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Cursor movement features\n",
    "    print(\"  - Cursor movement features\")\n",
    "    cursor_feat = cursor_movement_features(df)\n",
    "    features = features.merge(cursor_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Rolling features\n",
    "    print(\"  - Rolling window features\")\n",
    "    rolling_feat = rolling_features(df, window=10)\n",
    "    features = features.merge(rolling_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Action time distribution features\n",
    "    print(\"  - Action time distribution features\")\n",
    "    action_dist_feat = action_time_distribution_features(df)\n",
    "    features = features.merge(action_dist_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Word count velocity features\n",
    "    print(\"  - Word count velocity features\")\n",
    "    word_vel_feat = word_count_velocity_features(df)\n",
    "    features = features.merge(word_vel_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Activity timing features\n",
    "    print(\"  - Activity timing features\")\n",
    "    activity_time_feat = activity_timing_features(df)\n",
    "    features = features.merge(activity_time_feat, on=\"id\", how=\"left\")\n",
    "    \n",
    "    # Fill NaN and inf values\n",
    "    features = features.fillna(0)\n",
    "    features = features.replace([np.inf, -np.inf], 0)\n",
    "    \n",
    "    print(f\"\\nTotal features extracted: {features.shape[1] - 1}\")  # -1 for id column\n",
    "    print(f\"Total samples: {features.shape[0]}\")\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76158b",
   "metadata": {},
   "source": [
    "## 4. Load Data & Extract Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba0938e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7702047 rows from ..\\data\\train_logs_clean.csv\n",
      "Unique IDs: 2471\n",
      "\n",
      "Columns: ['Unnamed: 0', 'id', 'event_id', 'down_time', 'up_time', 'action_time', 'activity', 'down_event', 'up_event', 'text_change', 'cursor_position', 'word_count', 'id_encoded']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>event_id</th>\n",
       "      <th>down_time</th>\n",
       "      <th>up_time</th>\n",
       "      <th>action_time</th>\n",
       "      <th>activity</th>\n",
       "      <th>down_event</th>\n",
       "      <th>up_event</th>\n",
       "      <th>text_change</th>\n",
       "      <th>cursor_position</th>\n",
       "      <th>word_count</th>\n",
       "      <th>id_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>001519c8</td>\n",
       "      <td>1</td>\n",
       "      <td>60147.0</td>\n",
       "      <td>60238.0</td>\n",
       "      <td>91</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>001519c8</td>\n",
       "      <td>2</td>\n",
       "      <td>60657.0</td>\n",
       "      <td>60784.0</td>\n",
       "      <td>127</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>001519c8</td>\n",
       "      <td>3</td>\n",
       "      <td>60757.0</td>\n",
       "      <td>60861.0</td>\n",
       "      <td>104</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>001519c8</td>\n",
       "      <td>4</td>\n",
       "      <td>60930.0</td>\n",
       "      <td>61057.0</td>\n",
       "      <td>127</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>001519c8</td>\n",
       "      <td>5</td>\n",
       "      <td>61120.0</td>\n",
       "      <td>61227.0</td>\n",
       "      <td>107</td>\n",
       "      <td>Input</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>q</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        id  event_id  down_time  up_time  action_time activity  \\\n",
       "0           0  001519c8         1    60147.0  60238.0           91    Input   \n",
       "1           1  001519c8         2    60657.0  60784.0          127    Input   \n",
       "2           2  001519c8         3    60757.0  60861.0          104    Input   \n",
       "3           3  001519c8         4    60930.0  61057.0          127    Input   \n",
       "4           4  001519c8         5    61120.0  61227.0          107    Input   \n",
       "\n",
       "  down_event up_event text_change  cursor_position  word_count  id_encoded  \n",
       "0          q        q           q                1           1           0  \n",
       "1          q        q           q                2           1           0  \n",
       "2          q        q           q                3           1           0  \n",
       "3          q        q           q                4           1           0  \n",
       "4          q        q           q                5           1           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load cleaned training logs\n",
    "train_logs_path = Path('../data') / 'train_logs_clean.csv'\n",
    "\n",
    "if not train_logs_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"{train_logs_path} not found. \"\n",
    "        \"Please run Preprocessing.ipynb or preprocess/preprocess.py first to generate the cleaned data.\"\n",
    "    )\n",
    "\n",
    "train_logs = pd.read_csv(train_logs_path)\n",
    "print(f\"Loaded {len(train_logs)} rows from {train_logs_path}\")\n",
    "print(f\"Unique IDs: {train_logs['id'].nunique()}\")\n",
    "print(f\"\\nColumns: {list(train_logs.columns)}\")\n",
    "train_logs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45caee1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building all features...\n",
      "  - Base features\n",
      "  - Pause features\n",
      "  - Burst features\n",
      "  - P-burst features\n",
      "  - Activity sequence features\n",
      "  - Text change features\n",
      "  - Time-based features\n",
      "  - Keystroke velocity features\n",
      "  - Revision pattern features\n",
      "  - Cursor movement features\n",
      "  - Rolling window features\n",
      "  - Action time distribution features\n",
      "  - Word count velocity features\n",
      "  - Activity timing features\n",
      "\n",
      "Total features extracted: 122\n",
      "Total samples: 2471\n"
     ]
    }
   ],
   "source": [
    "# Extract all behavioural features\n",
    "train_features = build_all_features(train_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766cb439",
   "metadata": {},
   "source": [
    "## 5. Inspect Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456d39b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (2471, 123)\n",
      "\n",
      "Feature names (123 total):\n",
      "['id', 'events_count', 'total_time', 'total_chars', 'mean_action_time', 'std_action_time', 'max_action_time', 'min_action_time', 'backspace_count', 'paste_count', 'input_count', 'move_count', 'replace_count', 'nonproduction_count', 'cursor_pos_mean', 'cursor_pos_std', 'cursor_pos_max', 'word_count_mean', 'word_count_std', 'word_count_diff', 'chars_per_min', 'events_per_min', 'backspace_ratio', 'paste_ratio', 'replace_ratio', 'nonproduction_ratio', 'revision_ratio', 'pause_2s_count', 'pause_5s_count', 'pause_10s_count', 'mean_pause', 'median_pause', 'std_pause', 'max_pause', 'min_pause', 'avg_burst', 'max_burst', 'std_burst', 'avg_words_per_p_burst', 'input_to_remove_trans', 'remove_to_input_trans', 'input_to_input_trans', 'paste_to_input_trans', 'max_input_streak', 'max_remove_streak', 'unique_activities', 'activity_switches', 'activity_switch_rate', 'total_text_produced', 'total_text_removed', 'text_production_rate', 'text_removal_rate', 'max_text_addition', 'max_text_removal', 'text_volatility', 'positive_text_changes', 'negative_text_changes', 'text_removal_ratio', 'net_text_production', 'text_efficiency', 'early_events', 'middle_events', 'late_events', 'early_input_ratio', 'middle_input_ratio', 'late_input_ratio', 'early_remove_ratio', 'late_remove_ratio', 'middle_paste_ratio', 'late_phase_activity', 'input_iki_mean', 'input_iki_std', 'input_iki_median', 'input_iki_min', 'input_iki_max', 'fast_keystrokes', 'moderate_keystrokes', 'slow_keystrokes', 'keystroke_consistency', 'fast_keystroke_ratio', 'typing_rhythm_score', 'revisions_at_start', 'revisions_at_middle', 'revisions_at_end', 'total_revisions', 'review_cycles', 'backward_movements', 'early_revision_ratio', 'end_revision_ratio', 'revision_density', 'avg_cursor_jump', 'max_cursor_jump', 'total_cursor_movement', 'small_cursor_jumps', 'medium_cursor_jumps', 'large_cursor_jumps', 'cursor_jump_std', 'cursor_at_end_ratio', 'cursor_at_start_ratio', 'forward_writing_tendency', 'navigation_complexity', 'action_time_rolling_mean', 'action_time_rolling_std', 'word_count_rolling_trend', 'action_time_trend', 'action_time_acceleration', 'action_time_q25', 'action_time_q75', 'action_time_iqr', 'action_time_skew', 'action_time_kurtosis', 'avg_word_velocity', 'max_word_velocity', 'min_word_velocity', 'std_word_velocity', 'positive_velocity_ratio', 'input_time_total', 'remove_time_total', 'paste_time_total', 'nonprod_time_total', 'input_time_ratio', 'remove_time_ratio', 'productive_time_ratio']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>events_count</th>\n",
       "      <th>total_time</th>\n",
       "      <th>total_chars</th>\n",
       "      <th>mean_action_time</th>\n",
       "      <th>std_action_time</th>\n",
       "      <th>max_action_time</th>\n",
       "      <th>min_action_time</th>\n",
       "      <th>backspace_count</th>\n",
       "      <th>paste_count</th>\n",
       "      <th>...</th>\n",
       "      <th>min_word_velocity</th>\n",
       "      <th>std_word_velocity</th>\n",
       "      <th>positive_velocity_ratio</th>\n",
       "      <th>input_time_total</th>\n",
       "      <th>remove_time_total</th>\n",
       "      <th>paste_time_total</th>\n",
       "      <th>nonprod_time_total</th>\n",
       "      <th>input_time_ratio</th>\n",
       "      <th>remove_time_ratio</th>\n",
       "      <th>productive_time_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001519c8</td>\n",
       "      <td>2437</td>\n",
       "      <td>1642273.0</td>\n",
       "      <td>256</td>\n",
       "      <td>114.377103</td>\n",
       "      <td>43.028957</td>\n",
       "      <td>529</td>\n",
       "      <td>0</td>\n",
       "      <td>417</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037037</td>\n",
       "      <td>0.003130</td>\n",
       "      <td>0.142447</td>\n",
       "      <td>243731</td>\n",
       "      <td>34130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.874409</td>\n",
       "      <td>0.122445</td>\n",
       "      <td>0.874409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022f953</td>\n",
       "      <td>2200</td>\n",
       "      <td>1478848.0</td>\n",
       "      <td>323</td>\n",
       "      <td>118.913636</td>\n",
       "      <td>34.981016</td>\n",
       "      <td>502</td>\n",
       "      <td>22</td>\n",
       "      <td>260</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>237891</td>\n",
       "      <td>23550</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.909331</td>\n",
       "      <td>0.090019</td>\n",
       "      <td>0.909602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0042269b</td>\n",
       "      <td>3961</td>\n",
       "      <td>1607528.0</td>\n",
       "      <td>404</td>\n",
       "      <td>97.765716</td>\n",
       "      <td>37.383586</td>\n",
       "      <td>507</td>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012048</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.138384</td>\n",
       "      <td>353718</td>\n",
       "      <td>32905</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913408</td>\n",
       "      <td>0.084971</td>\n",
       "      <td>0.913408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0059420b</td>\n",
       "      <td>1457</td>\n",
       "      <td>1282520.0</td>\n",
       "      <td>206</td>\n",
       "      <td>128.026081</td>\n",
       "      <td>113.326188</td>\n",
       "      <td>806</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.018480</td>\n",
       "      <td>0.166896</td>\n",
       "      <td>167790</td>\n",
       "      <td>18410</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899509</td>\n",
       "      <td>0.098695</td>\n",
       "      <td>0.900367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0075873a</td>\n",
       "      <td>2459</td>\n",
       "      <td>1501522.0</td>\n",
       "      <td>252</td>\n",
       "      <td>124.731192</td>\n",
       "      <td>60.132026</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.004898</td>\n",
       "      <td>0.137510</td>\n",
       "      <td>266515</td>\n",
       "      <td>40199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868934</td>\n",
       "      <td>0.131063</td>\n",
       "      <td>0.868934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 123 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  events_count  total_time  total_chars  mean_action_time  \\\n",
       "0  001519c8          2437   1642273.0          256        114.377103   \n",
       "1  0022f953          2200   1478848.0          323        118.913636   \n",
       "2  0042269b          3961   1607528.0          404         97.765716   \n",
       "3  0059420b          1457   1282520.0          206        128.026081   \n",
       "4  0075873a          2459   1501522.0          252        124.731192   \n",
       "\n",
       "   std_action_time  max_action_time  min_action_time  backspace_count  \\\n",
       "0        43.028957              529                0              417   \n",
       "1        34.981016              502               22              260   \n",
       "2        37.383586              507                1              439   \n",
       "3       113.326188              806                0              151   \n",
       "4        60.132026              701                0              517   \n",
       "\n",
       "   paste_count  ...  min_word_velocity  std_word_velocity  \\\n",
       "0            0  ...          -0.037037           0.003130   \n",
       "1            1  ...          -0.032258           0.002989   \n",
       "2            0  ...          -0.012048           0.009014   \n",
       "3            1  ...          -0.333333           0.018480   \n",
       "4            0  ...          -0.041667           0.004898   \n",
       "\n",
       "   positive_velocity_ratio  input_time_total  remove_time_total  \\\n",
       "0                 0.142447            243731              34130   \n",
       "1                 0.167349            237891              23550   \n",
       "2                 0.138384            353718              32905   \n",
       "3                 0.166896            167790              18410   \n",
       "4                 0.137510            266515              40199   \n",
       "\n",
       "   paste_time_total  nonprod_time_total  input_time_ratio  remove_time_ratio  \\\n",
       "0                 0                   0          0.874409           0.122445   \n",
       "1                71                   0          0.909331           0.090019   \n",
       "2                 0                   0          0.913408           0.084971   \n",
       "3               160                   0          0.899509           0.098695   \n",
       "4                 0                   0          0.868934           0.131063   \n",
       "\n",
       "   productive_time_ratio  \n",
       "0               0.874409  \n",
       "1               0.909602  \n",
       "2               0.913408  \n",
       "3               0.900367  \n",
       "4               0.868934  \n",
       "\n",
       "[5 rows x 123 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(f\"Feature matrix shape: {train_features.shape}\")\n",
    "print(f\"\\nFeature names ({len(train_features.columns)} total):\")\n",
    "print(list(train_features.columns))\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "753b0a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "0\n",
      "\n",
      "Infinite values per column:\n",
      "0\n",
      "\n",
      "Basic statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>events_count</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>3.116976e+03</td>\n",
       "      <td>1422.373961</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>2.000500e+03</td>\n",
       "      <td>2.826000e+03</td>\n",
       "      <td>3.962000e+03</td>\n",
       "      <td>1.246200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_time</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>1.482786e+06</td>\n",
       "      <td>341787.101803</td>\n",
       "      <td>111533.000000</td>\n",
       "      <td>1.342593e+06</td>\n",
       "      <td>1.579254e+06</td>\n",
       "      <td>1.700642e+06</td>\n",
       "      <td>4.854776e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_chars</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>3.899664e+02</td>\n",
       "      <td>172.455317</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>2.550000e+02</td>\n",
       "      <td>3.510000e+02</td>\n",
       "      <td>4.800000e+02</td>\n",
       "      <td>1.326000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_action_time</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>1.025759e+02</td>\n",
       "      <td>24.248241</td>\n",
       "      <td>6.112604</td>\n",
       "      <td>8.581431e+01</td>\n",
       "      <td>9.990975e+01</td>\n",
       "      <td>1.168673e+02</td>\n",
       "      <td>2.203022e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_action_time</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>4.414056e+01</td>\n",
       "      <td>47.414987</td>\n",
       "      <td>8.352781</td>\n",
       "      <td>3.335606e+01</td>\n",
       "      <td>3.998542e+01</td>\n",
       "      <td>4.745514e+01</td>\n",
       "      <td>1.817442e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paste_time_total</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>2.473695e+01</td>\n",
       "      <td>102.280410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.931000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nonprod_time_total</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>input_time_ratio</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>9.072264e-01</td>\n",
       "      <td>0.051237</td>\n",
       "      <td>0.299042</td>\n",
       "      <td>8.809321e-01</td>\n",
       "      <td>9.161550e-01</td>\n",
       "      <td>9.429181e-01</td>\n",
       "      <td>9.992888e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remove_time_ratio</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>9.201967e-02</td>\n",
       "      <td>0.051207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.638033e-02</td>\n",
       "      <td>8.321194e-02</td>\n",
       "      <td>1.178878e-01</td>\n",
       "      <td>7.006388e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>productive_time_ratio</th>\n",
       "      <td>2471.0</td>\n",
       "      <td>9.073216e-01</td>\n",
       "      <td>0.051235</td>\n",
       "      <td>0.299042</td>\n",
       "      <td>8.811736e-01</td>\n",
       "      <td>9.162125e-01</td>\n",
       "      <td>9.430334e-01</td>\n",
       "      <td>9.992888e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count          mean            std            min  \\\n",
       "events_count           2471.0  3.116976e+03    1422.373961     253.000000   \n",
       "total_time             2471.0  1.482786e+06  341787.101803  111533.000000   \n",
       "total_chars            2471.0  3.899664e+02     172.455317      35.000000   \n",
       "mean_action_time       2471.0  1.025759e+02      24.248241       6.112604   \n",
       "std_action_time        2471.0  4.414056e+01      47.414987       8.352781   \n",
       "...                       ...           ...            ...            ...   \n",
       "paste_time_total       2471.0  2.473695e+01     102.280410       0.000000   \n",
       "nonprod_time_total     2471.0  0.000000e+00       0.000000       0.000000   \n",
       "input_time_ratio       2471.0  9.072264e-01       0.051237       0.299042   \n",
       "remove_time_ratio      2471.0  9.201967e-02       0.051207       0.000000   \n",
       "productive_time_ratio  2471.0  9.073216e-01       0.051235       0.299042   \n",
       "\n",
       "                                25%           50%           75%           max  \n",
       "events_count           2.000500e+03  2.826000e+03  3.962000e+03  1.246200e+04  \n",
       "total_time             1.342593e+06  1.579254e+06  1.700642e+06  4.854776e+06  \n",
       "total_chars            2.550000e+02  3.510000e+02  4.800000e+02  1.326000e+03  \n",
       "mean_action_time       8.581431e+01  9.990975e+01  1.168673e+02  2.203022e+02  \n",
       "std_action_time        3.335606e+01  3.998542e+01  4.745514e+01  1.817442e+03  \n",
       "...                             ...           ...           ...           ...  \n",
       "paste_time_total       0.000000e+00  0.000000e+00  0.000000e+00  1.931000e+03  \n",
       "nonprod_time_total     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "input_time_ratio       8.809321e-01  9.161550e-01  9.429181e-01  9.992888e-01  \n",
       "remove_time_ratio      5.638033e-02  8.321194e-02  1.178878e-01  7.006388e-01  \n",
       "productive_time_ratio  8.811736e-01  9.162125e-01  9.430334e-01  9.992888e-01  \n",
       "\n",
       "[122 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for any issues\n",
    "print(\"Missing values per column:\")\n",
    "print(train_features.isnull().sum().sum())\n",
    "print(\"\\nInfinite values per column:\")\n",
    "print(np.isinf(train_features.select_dtypes(include=[np.number])).sum().sum())\n",
    "print(\"\\nBasic statistics:\")\n",
    "train_features.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abaa9d4",
   "metadata": {},
   "source": [
    "## 6. Save Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b1d1c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2471 samples with 123 features to ..\\data\\train_behaviour_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Save behavioural features to CSV\n",
    "output_path = Path('../data') / 'train_behaviour_features.csv'\n",
    "train_features.to_csv(output_path, index=False)\n",
    "print(f\"Saved {train_features.shape[0]} samples with {train_features.shape[1]} features to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8abee1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook extracts **comprehensive behavioural features** from keystroke logging data. The features capture:\n",
    "\n",
    "### Feature Categories (150+ features total):\n",
    "\n",
    "1. **Base Features**: Event counts, total time, typing speed, activity ratios\n",
    "2. **Pause Features**: Gaps between keystrokes at different thresholds (2s, 5s, 10s)\n",
    "3. **Burst Features**: When they're typing continuously and how fluently\n",
    "4. **Activity Sequence**: How activities transition from one to another, streaks, variety\n",
    "5. **Text Change**: How fast they produce/remove text, editing efficiency\n",
    "6. **Temporal Patterns**: What they do in early/middle/late stages\n",
    "7. **Keystroke Velocity**: Typing speed variations, rhythm, consistency\n",
    "8. **Word Count Velocity**: How the word count changes over time\n",
    "9. **Activity Timing**: How much time on each type of activity\n",
    "10. **Revision Patterns**: Where they edit, review cycles, going backwards\n",
    "11. **Cursor Movement**: How they navigate around, jump distances\n",
    "12. **Rolling Window**: Trends and changes in typing behaviour\n",
    "13. **Distribution Features**: Statistical properties (skew, kurtosis, IQR)\n",
    "\n",
    "### Output:\n",
    "\n",
    "- `data/train_behaviour_features.csv` - One row per essay ID with all behavioural features\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Combine with text features from `FeatureExtraction_Essay.ipynb`\n",
    "- Merge with TF-IDF/SVD features from `tfidf/tfidf.ipynb`\n",
    "- Build predictive models using these features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
