{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39b68f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id       activity\n",
      "0  001519c8  Nonproduction\n",
      "1  001519c8  Nonproduction\n",
      "2  001519c8  Nonproduction\n",
      "         id                                          operation\n",
      "0  001519c8  NNNIIIIIIIIIIIIIIIRIIIIIIIIIIIIIIRIIIIIIIIIIII...\n",
      "1  0022f953  NNIIIIIIIINIIIIIIIIIIIRRRRRRRRRRRIIIIIIIIIIIII...\n",
      "2  0042269b  NNIIIIIIIIIIIIIIIIIIIIIIIIIIIIIINIIIIIIIIIIIII...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18138\\AppData\\Local\\Temp\\ipykernel_117348\\2693275798.py:17: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(rebuild_text)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"train_logs_clean.csv\")\n",
    "\n",
    "df = df[['id', 'activity']]\n",
    "\n",
    "print(df.head(3))\n",
    "\n",
    "def rebuild_text(grp):\n",
    "    buf = []\n",
    "    for op in grp['activity']:\n",
    "        buf.append(op[0])\n",
    "    return \"\".join(buf)\n",
    "\n",
    "operations = (\n",
    "    df.groupby('id')\n",
    "        .apply(rebuild_text)\n",
    "        .reset_index(name='operation')\n",
    ")\n",
    "\n",
    "print(operations.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c510841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id       iii      iiii     iiiii     iiiin  iiiip     iiiir  \\\n",
      "0  001519c8  0.605252  0.567680  0.533865  0.008549    0.0  0.025306   \n",
      "1  0022f953  0.604434  0.569855  0.537745  0.012012    0.0  0.020137   \n",
      "2  0042269b  0.596965  0.574090  0.551953  0.009420    0.0  0.012744   \n",
      "3  0059420b  0.607514  0.572120  0.537782  0.005818    0.0  0.028032   \n",
      "4  0075873a  0.583251  0.561007  0.539744  0.011136    0.0  0.010153   \n",
      "\n",
      "       iiin     iiini  iiinm  ...     rrrnr  rrrp  rrrpi  rrrpn  rrrpr  \\\n",
      "0  0.011281  0.002406    0.0  ...  0.000000   0.0    0.0    0.0    0.0   \n",
      "1  0.012713  0.007100    0.0  ...  0.000000   0.0    0.0    0.0    0.0   \n",
      "2  0.009601  0.004454    0.0  ...  0.001269   0.0    0.0    0.0    0.0   \n",
      "3  0.005816  0.003189    0.0  ...  0.000000   0.0    0.0    0.0    0.0   \n",
      "4  0.011786  0.005595    0.0  ...  0.000000   0.0    0.0    0.0    0.0   \n",
      "\n",
      "       rrrr     rrrri     rrrrn  rrrrp     rrrrr  \n",
      "0  0.070962  0.009974  0.001926    0.0  0.059571  \n",
      "1  0.034351  0.005329  0.001990    0.0  0.027390  \n",
      "2  0.044991  0.005758  0.001249    0.0  0.038311  \n",
      "3  0.024389  0.004787  0.000000    0.0  0.019705  \n",
      "4  0.129026  0.006917  0.000738    0.0  0.122017  \n",
      "\n",
      "[5 rows x 871 columns]\n",
      "         id        00        01        02        03        04        05  \\\n",
      "0  001519c8  0.996500 -0.051572  0.053250  0.026710 -0.004565 -0.002286   \n",
      "1  0022f953  0.999176  0.025000 -0.017389  0.017096 -0.005643  0.012513   \n",
      "2  0042269b  0.998002 -0.059992 -0.003995 -0.015051 -0.002213  0.002277   \n",
      "3  0059420b  0.998196 -0.018568 -0.030928  0.036801  0.004085 -0.008201   \n",
      "4  0075873a  0.986850 -0.062120  0.140430 -0.045986 -0.002615  0.005094   \n",
      "\n",
      "         06        07        08  ...        54        55        56        57  \\\n",
      "0 -0.007645 -0.013857  0.007615  ... -0.000101  0.003765  0.000342 -0.000920   \n",
      "1 -0.002095 -0.003364  0.001420  ...  0.000114  0.000478 -0.000805  0.000009   \n",
      "2 -0.003712 -0.006925  0.002739  ...  0.000413 -0.000253  0.000029 -0.000130   \n",
      "3  0.021885 -0.004283 -0.003572  ... -0.002463  0.002604  0.001370  0.000020   \n",
      "4  0.002056 -0.002291 -0.002244  ...  0.000266  0.000202 -0.000062 -0.000985   \n",
      "\n",
      "         58        59        60        61        62        63  \n",
      "0 -0.000695  0.000109  0.001787 -0.000253 -0.001913 -0.001325  \n",
      "1 -0.000727 -0.000655  0.000538 -0.000432  0.000630 -0.000237  \n",
      "2 -0.000826  0.001097 -0.000511  0.000768 -0.000243 -0.000172  \n",
      "3  0.000161 -0.000118 -0.000700 -0.000771  0.000104 -0.000608  \n",
      "4  0.000299 -0.000303  0.001137 -0.000553 -0.000974 -0.000627  \n",
      "\n",
      "[5 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF + SVD for operation feature extraction\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(3, 5),\n",
    "    max_features=30000,\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(operations['operation'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    X_tfidf.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "tfidf_df.insert(0, 'id', operations['id'])\n",
    "\n",
    "print(tfidf_df.head())\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svdsize = 64\n",
    "\n",
    "svd = TruncatedSVD(\n",
    "    n_components=svdsize,\n",
    "    random_state=42,\n",
    "    n_iter=7\n",
    ")\n",
    "\n",
    "X_svd = svd.fit_transform(X_tfidf)\n",
    "\n",
    "svd_df = pd.DataFrame(\n",
    "    X_svd,\n",
    "    columns=[f'{i:02d}' for i in range(svdsize)]\n",
    ")\n",
    "svd_df.insert(0, 'id', operations['id'].values)\n",
    "\n",
    "print(svd_df.head())\n",
    "svd_df.to_csv(\"operations_tfidf_svd_vectors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aecd6a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id activity\n",
      "0  0000aaaa    Input\n",
      "1  0000aaaa    Input\n",
      "2  2222bbbb    Input\n",
      "         id operation\n",
      "0  0000aaaa        II\n",
      "1  2222bbbb        II\n",
      "2  4444cccc        II\n",
      "         id   00   01   02   03   04   05   06   07   08  ...   54   55   56  \\\n",
      "0  0000aaaa  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "1  2222bbbb  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2  4444cccc  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "    57   58   59   60   61   62   63  \n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "\n",
      "[3 rows x 65 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18138\\AppData\\Local\\Temp\\ipykernel_117348\\2629927440.py:15: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(rebuild_text)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"test_logs_clean.csv\")\n",
    "\n",
    "df = df[['id', 'activity']]\n",
    "\n",
    "print(df.head(3))\n",
    "\n",
    "def rebuild_text(grp):\n",
    "    buf = []\n",
    "    for op in grp['activity']:\n",
    "        buf.append(op[0])\n",
    "    return \"\".join(buf)\n",
    "\n",
    "operations = (\n",
    "    df.groupby('id')\n",
    "        .apply(rebuild_text)\n",
    "        .reset_index(name='operation')\n",
    ")\n",
    "\n",
    "print(operations.head(3))\n",
    "\n",
    "test_tfidf = vectorizer.transform(operations['operation'])\n",
    "\n",
    "test_svd = svd.transform(test_tfidf)\n",
    "\n",
    "test_svd_df = pd.DataFrame(\n",
    "    test_svd,\n",
    "    columns=[f'{i:02d}' for i in range(svdsize)]\n",
    ")\n",
    "test_svd_df.insert(0, 'id', operations['id'].values)\n",
    "\n",
    "test_svd_df.to_csv(\"test_operations_tfidf_svd_vectors.csv\", index=False)\n",
    "\n",
    "print(test_svd_df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
